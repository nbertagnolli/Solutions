\Large\textbf{Problem 3}
The Probability of Selecting an Apple can be decomposed as:
\begin{align*}
\prob(apple) &= \prob(apple, red) + \prob(apple, blue) + prob(apple, green)\\ 
&= \prob(apple | red)\prob(red) + \prob(apple | blue) \prob(blue) + \prob(apple | green)\prob(green)\\
&= (.3)(.2) +(.5)(.2) + (.3)(.6)\\
&= .34
\end{align*}

The probability that observing an orange came from the green box can be solved using Bayes rule:

\begin{align*}
\prob(green | orange) &= \frac{\prob(orange | green)\prob(green)}{\prob(orange)}\\
&= \frac{(.3)(.6)}{.66}\\
&= .27
\end{align*}

\Large\textbf{Problem 5}
\begin{align*}
  \var{X} &= \Exp{(X - \Exp{X})^2}\\
  &= \Exp{X^2 - 2X\Exp{X} + \Exp{X}^2}  && \text{Distributive Law}\\
  &= \Exp{X^2} + \Exp{-2X\Exp{X}} + \Exp{\Exp{X}^2}  && \text{Linearity of } \Exp{X}\\
  &= \Exp{X^2} + -2\Exp{X\Exp{X}} + \Exp{X}^2  && \Exp{\alpha X} = \alpha\Exp{X}\\
  &= \Exp{X^2} + -2\Exp{X}^2 + \Exp{X}^2 && \Exp{X}\text{ is just another constant see above}\\
  &= \Exp{X^2} -\Exp{X}^2\\
\end{align*}

\Large\textbf{Problem 6}

$\cov{X,Y} = \Exp{X,Y} - \Exp{X}\Exp{Y}$ But because $X \perp Y \Rightarrow \Exp{X,Y} = \Exp{X}\Exp{Y} \Rightarrow \cov{X,Y} = 0$

\Large\textbf{Problem 7}
\begin{align*}
 I^2 &= \int_{-\infty}^\infty\int_{-\infty}^\infty \exp\left(-\frac{1}{2\sigma^2}x^2-\frac{1}{2\sigma^2}y^2\right)dxdy\\
 &= \int_{-\infty}^\infty\int_{-\infty}^\infty \exp\left(-\frac{1}{2\sigma^2}(x^2 + y^2)\right)dxdy\\\\
 &= \int_{0}^\infty\int_{0}^{2\pi} \exp\left(-\frac{1}{2\sigma^2}\left[r^2\cos^2(\theta) + r^2\sin^2(\theta)\right]\right)rd\theta dr\\
 &= \int_{0}^\infty\int_{0}^{2\pi} \exp\left(-\frac{r^2}{2\sigma^2}\right)rd\theta dr\\
 &=2\pi\int_{0}^\infty \exp\left(-\frac{r^2}{2\sigma^2}\right)rdr\\
 &= 2\pi\int_{0}^\infty \exp\left(-\frac{u}{2\sigma^2}\right)\frac{1}{2}  du\\
 &= -2\pi\sigma^2 \exp\left(-\frac{u}{2\sigma^2}\right) |_0^{\infty}\\
 &= 2\pi\sigma^2
\end{align*}

Now we just need to show that this normalizes the Gaussian.  Take $y = x-\mu$ then

\begin{align*}
\mathcal{N}(x|\mu, \sigma^2) &= \int_{-\infty}^\infty\frac{1}{\sqrt{2\pi\sigma^2}}\exp\left(-\frac{1}{2\sigma^2}(x-\mu)^2\right)dx\\
&= \int_{-\infty}^\infty\frac{1}{\sqrt{2\pi\sigma^2}}\exp\left(-\frac{1}{2\sigma^2}y^2\right)dy\\
\end{align*}

\Large\textbf{Problem 8}

\Large\textbf{Problem 9}
\begin{align*}
\mathcal{N}(x|\mu, \sigma^2) &= \frac{1}{\sqrt{2\pi\sigma^2}}\exp\left(-\frac{1}{2\sigma^2}(x-\mu)^2\right)\\
\frac{d\mathcal{N}(x|\mu, \sigma^2)}{dx} &= -\frac{1}{\sigma^2}\mathcal{N}(x|\mu, \sigma^2)(x-\mu)\\
0 &= \mathcal{N}(x|\mu, \sigma^2)(x-\mu)
\end{align*}

But since $\mathcal{N}(x|\mu, \sigma^2)(x-\mu) > 0$ the only term that matters is $(x-\mu)$, which goes to 0 at $x=\mu$

The proof for the multivariate case is almost identical and is omitted


\Large\textbf{Problem 10}
\begin{align*}
  \log p(\x|\mu, \sigma^2) &= -\frac{1}{\sqrt{2\pi\sigma^2}}\sum_{n=1}^N(x_n-\mu)^2 - \frac{N}{2}\log\sigma^2 - \frac{N}{2}\log(2\pi)\\
  \frac{d\log p(\x|\mu, \sigma^2)}{d\mu} &= -\frac{1}{\sqrt{\pi\sigma^2}}\sum_{n=1}^N(x_n-\mu)\\
  0 &= \sum_{n=1}^N(x_n-\mu)\\
  &= \sum_{n=1}^Nx_n- \sum_{n=1}^N\mu\\
  \mu &= \sum_{n=1}^Nx_n
\end{align*}








